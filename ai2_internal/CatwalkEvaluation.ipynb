{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b6b6e8",
   "metadata": {},
   "source": [
    "# Catwalk LLM evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1e7b8",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11dba4",
   "metadata": {},
   "source": [
    "Follow the README to checkout repo, set up beaker secrets for github/google sheets, install gantry, etc. \n",
    "\n",
    "Run this notebook in the associated ai2-olmo-eval conda environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05aa85c",
   "metadata": {},
   "source": [
    "## Local setup (edit on first time use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e9e7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for the local repository where gantry will be run from\n",
    "MY_REPO_DIR = \"/Users/yulingg/desktop/llm-eval-yulingg/ai2-olmo-eval/\" ## NOTE: CHANGE THIS to your local repo path!\n",
    "\n",
    "MY_DEFAULT_CATWALK_OPTIONS = {\n",
    "    \"gsheet\": \"Catwalk_Evaluation_yulingg\", ## NOTE: CHANGE THIS to the google sheet you want to write to!\n",
    "    \"split\": \"validation\",\n",
    "    \"batch-size\": 32,\n",
    "    \"random-subsample-seed\": 1234,\n",
    "    \"model-max-length\": 2048,\n",
    "    \"max-batch-tokens\": 20480\n",
    "}\n",
    "\n",
    "MY_DEFAULT_GANTRY_OPTIONS = {\n",
    "    \"workspace\": \"ai2/yulingg-llm-eval\", ## NOTE: CHANGE THIS to the beaker workspace you want to use!\n",
    "    \"beaker-image\": \"oyvindt/ai2-olmo-eval-image\", # keep\n",
    "    \"beaker-dataset-cache\": \"/net/nfs.cirrascale/aristo/oyvindt/hf_datasets_cache\", # keep\n",
    "    \"cluster\": \"ai2/aristo-cirrascale\" # run on cirrascale machines for dataset cache to work\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a35deb",
   "metadata": {},
   "source": [
    "## Load code dependencies (run first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "962e686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(MY_REPO_DIR, \"ai2_internal\"))\n",
    "\n",
    "import utils_internal\n",
    "from utils_internal import *\n",
    "from task_library import *\n",
    "from model_library import *\n",
    "\n",
    "utils_internal.REPO_DIR = MY_REPO_DIR\n",
    "utils_internal.DEFAULT_CATWALK_OPTIONS = MY_DEFAULT_CATWALK_OPTIONS\n",
    "utils_internal.DEFAULT_GANTRY_OPTIONS = MY_DEFAULT_GANTRY_OPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de845679",
   "metadata": {},
   "source": [
    "## Simple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9127fd",
   "metadata": {},
   "source": [
    "Specify model and task directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf041df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running lmeval-pythia-160m-step140000-f0f04321b8\n"
     ]
    }
   ],
   "source": [
    "model_specs = {\"name\": \"EleutherAI/pythia-160m\", \"checkpoint\": \"step140000\"}\n",
    "task_specs = {\"task\": \"arc_challenge arc_easy\", \"limit\": 1000, \"num-shots\": 0}\n",
    "\n",
    "res = run_catwalk(model_specs, task_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bb2b8",
   "metadata": {},
   "source": [
    "Use model and task library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3c0cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running lmeval-pythia-160m-step140000-ee8f7f6d24\n"
     ]
    }
   ],
   "source": [
    "res = run_catwalk(MODEL_SPECS[\"pythia-160m-step140000\"], TASK_SPECS[\"rc20_n0_val1000\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512247ea",
   "metadata": {},
   "source": [
    "## Sample data analysis from google sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e570bc-a176-4a63-9901-4edfbd3e767b",
   "metadata": {},
   "source": [
    "Load google sheet (need GDRIVE_SERVICE_ACCOUNT_JSON environment variable OR supply appropriate auth_file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "054ac846-cca7-4b3a-b8f0-e07c91f70b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = load_gsheet_as_df(MY_DEFAULT_CATWALK_OPTIONS['gsheet'], auth_file=\"/Users/yulingg/desktop/llm-eval-yulingg/downloaded_credentials_file.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c4b052d-0440-434c-b6cb-67f40adcf8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>model</th>\n",
       "      <th>model_kwargs</th>\n",
       "      <th>full_model</th>\n",
       "      <th>task</th>\n",
       "      <th>primary_metric</th>\n",
       "      <th>metric</th>\n",
       "      <th>processing_time</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>model_max_length</th>\n",
       "      <th>max_batch_tokens</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>limit</th>\n",
       "      <th>split</th>\n",
       "      <th>random_subsample_seed</th>\n",
       "      <th>num_shots</th>\n",
       "      <th>unconditioned_prompt</th>\n",
       "      <th>all_metrics</th>\n",
       "      <th>beaker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-09 05:12:46 UTC</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>{'revision': None, 'trust_remote_code': False}</td>\n",
       "      <td>lm::pretrained=llama2-7b</td>\n",
       "      <td>social_iqa</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>100.451221</td>\n",
       "      <td>1000</td>\n",
       "      <td>2048</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.465, \"predicted_indices_raw\": [[...</td>\n",
       "      <td>01HKP9VR07QZZ8HCJM1NP4QV96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-09 05:12:46 UTC</td>\n",
       "      <td>llama2-7b</td>\n",
       "      <td>{'revision': None, 'trust_remote_code': False}</td>\n",
       "      <td>lm::pretrained=llama2-7b</td>\n",
       "      <td>csqa</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>110.525418</td>\n",
       "      <td>1000</td>\n",
       "      <td>2048</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.587, \"predicted_indices_raw\": [[...</td>\n",
       "      <td>01HKP9VR07QZZ8HCJM1NP4QV96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-09 05:12:58 UTC</td>\n",
       "      <td>llama-7b</td>\n",
       "      <td>{'revision': None, 'trust_remote_code': False}</td>\n",
       "      <td>lm::pretrained=llama-7b</td>\n",
       "      <td>social_iqa</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>100.337260</td>\n",
       "      <td>1000</td>\n",
       "      <td>2048</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.469, \"predicted_indices_raw\": [[...</td>\n",
       "      <td>01HKP9VJ3VAERXS3X91X12RS42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-09 05:12:58 UTC</td>\n",
       "      <td>llama-7b</td>\n",
       "      <td>{'revision': None, 'trust_remote_code': False}</td>\n",
       "      <td>lm::pretrained=llama-7b</td>\n",
       "      <td>csqa</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>110.408994</td>\n",
       "      <td>1000</td>\n",
       "      <td>2048</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.589, \"predicted_indices_raw\": [[...</td>\n",
       "      <td>01HKP9VJ3VAERXS3X91X12RS42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-09 15:12:24 UTC</td>\n",
       "      <td>EleutherAI/pythia-160m</td>\n",
       "      <td>{'revision': 'step140000', 'trust_remote_code'...</td>\n",
       "      <td>lm::pretrained=EleutherAI/pythia-160m</td>\n",
       "      <td>arc_challenge</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.284281</td>\n",
       "      <td>3.800181</td>\n",
       "      <td>299</td>\n",
       "      <td>2048</td>\n",
       "      <td>20480</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.21070234113712374, \"predicted_in...</td>\n",
       "      <td>01HKQC8C9J6GSJTZ36GR3D5QBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2024-01-10 09:21:14 UTC</td>\n",
       "      <td>olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf</td>\n",
       "      <td>{'revision': None, 'trust_remote_code': False}</td>\n",
       "      <td>lm::pretrained=olmo-7b-v1_5-mix-mitch-ish-mosa...</td>\n",
       "      <td>wsc</td>\n",
       "      <td>acc_raw</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>12.721434</td>\n",
       "      <td>104</td>\n",
       "      <td>2048</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>{\"acc_raw\": 0.375, \"predicted_indices_raw\": [[...</td>\n",
       "      <td>01HKS6YZAHS5EY2RC43FBSZ07F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2024-01-10 14:37:41 UTC</td>\n",
       "      <td>olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf</td>\n",
       "      <td>{'revision': None, 'trust_remote_code': False}</td>\n",
       "      <td>lm::pretrained=olmo-7b-v1_5-mix-mitch-ish-mosa...</td>\n",
       "      <td>social_iqa</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>97.686666</td>\n",
       "      <td>1000</td>\n",
       "      <td>2048</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.457, \"predicted_indices_raw\": [[...</td>\n",
       "      <td>01HKSW4Y5X6R5VJ6ZPZ6HSJQFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2024-01-10 14:37:41 UTC</td>\n",
       "      <td>olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf</td>\n",
       "      <td>{'revision': None, 'trust_remote_code': False}</td>\n",
       "      <td>lm::pretrained=olmo-7b-v1_5-mix-mitch-ish-mosa...</td>\n",
       "      <td>csqa</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.618000</td>\n",
       "      <td>108.669518</td>\n",
       "      <td>1000</td>\n",
       "      <td>2048</td>\n",
       "      <td>4096</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.564, \"predicted_indices_raw\": [[...</td>\n",
       "      <td>01HKSW4Y5X6R5VJ6ZPZ6HSJQFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2024-01-23 02:44:54 UTC</td>\n",
       "      <td>EleutherAI/pythia-160m</td>\n",
       "      <td>{'revision': 'step140000', 'trust_remote_code'...</td>\n",
       "      <td>lm::pretrained=EleutherAI/pythia-160m</td>\n",
       "      <td>arc_challenge</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.284281</td>\n",
       "      <td>4.655930</td>\n",
       "      <td>299</td>\n",
       "      <td>2048</td>\n",
       "      <td>20480</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.21070234113712374, \"predicted_in...</td>\n",
       "      <td>01HMT2Y51AZECJQ7J996GCTFBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2024-01-23 02:44:54 UTC</td>\n",
       "      <td>EleutherAI/pythia-160m</td>\n",
       "      <td>{'revision': 'step140000', 'trust_remote_code'...</td>\n",
       "      <td>lm::pretrained=EleutherAI/pythia-160m</td>\n",
       "      <td>arc_easy</td>\n",
       "      <td>acc_uncond</td>\n",
       "      <td>0.407018</td>\n",
       "      <td>5.072799</td>\n",
       "      <td>570</td>\n",
       "      <td>2048</td>\n",
       "      <td>20480</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>validation</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer:</td>\n",
       "      <td>{\"acc_raw\": 0.4649122807017544, \"predicted_ind...</td>\n",
       "      <td>01HMT2Y51AZECJQ7J996GCTFBE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date                                            model  \\\n",
       "0    2024-01-09 05:12:46 UTC                                        llama2-7b   \n",
       "1    2024-01-09 05:12:46 UTC                                        llama2-7b   \n",
       "2    2024-01-09 05:12:58 UTC                                         llama-7b   \n",
       "3    2024-01-09 05:12:58 UTC                                         llama-7b   \n",
       "4    2024-01-09 15:12:24 UTC                           EleutherAI/pythia-160m   \n",
       "..                       ...                                              ...   \n",
       "353  2024-01-10 09:21:14 UTC  olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf   \n",
       "354  2024-01-10 14:37:41 UTC  olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf   \n",
       "355  2024-01-10 14:37:41 UTC  olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf   \n",
       "356  2024-01-23 02:44:54 UTC                           EleutherAI/pythia-160m   \n",
       "357  2024-01-23 02:44:54 UTC                           EleutherAI/pythia-160m   \n",
       "\n",
       "                                          model_kwargs  \\\n",
       "0       {'revision': None, 'trust_remote_code': False}   \n",
       "1       {'revision': None, 'trust_remote_code': False}   \n",
       "2       {'revision': None, 'trust_remote_code': False}   \n",
       "3       {'revision': None, 'trust_remote_code': False}   \n",
       "4    {'revision': 'step140000', 'trust_remote_code'...   \n",
       "..                                                 ...   \n",
       "353     {'revision': None, 'trust_remote_code': False}   \n",
       "354     {'revision': None, 'trust_remote_code': False}   \n",
       "355     {'revision': None, 'trust_remote_code': False}   \n",
       "356  {'revision': 'step140000', 'trust_remote_code'...   \n",
       "357  {'revision': 'step140000', 'trust_remote_code'...   \n",
       "\n",
       "                                            full_model           task  \\\n",
       "0                             lm::pretrained=llama2-7b     social_iqa   \n",
       "1                             lm::pretrained=llama2-7b           csqa   \n",
       "2                              lm::pretrained=llama-7b     social_iqa   \n",
       "3                              lm::pretrained=llama-7b           csqa   \n",
       "4                lm::pretrained=EleutherAI/pythia-160m  arc_challenge   \n",
       "..                                                 ...            ...   \n",
       "353  lm::pretrained=olmo-7b-v1_5-mix-mitch-ish-mosa...            wsc   \n",
       "354  lm::pretrained=olmo-7b-v1_5-mix-mitch-ish-mosa...     social_iqa   \n",
       "355  lm::pretrained=olmo-7b-v1_5-mix-mitch-ish-mosa...           csqa   \n",
       "356              lm::pretrained=EleutherAI/pythia-160m  arc_challenge   \n",
       "357              lm::pretrained=EleutherAI/pythia-160m       arc_easy   \n",
       "\n",
       "    primary_metric    metric  processing_time  num_instances  \\\n",
       "0       acc_uncond  0.480000       100.451221           1000   \n",
       "1       acc_uncond  0.629000       110.525418           1000   \n",
       "2       acc_uncond  0.489000       100.337260           1000   \n",
       "3       acc_uncond  0.626000       110.408994           1000   \n",
       "4       acc_uncond  0.284281         3.800181            299   \n",
       "..             ...       ...              ...            ...   \n",
       "353        acc_raw  0.375000        12.721434            104   \n",
       "354     acc_uncond  0.465000        97.686666           1000   \n",
       "355     acc_uncond  0.618000       108.669518           1000   \n",
       "356     acc_uncond  0.284281         4.655930            299   \n",
       "357     acc_uncond  0.407018         5.072799            570   \n",
       "\n",
       "     model_max_length  max_batch_tokens  batch_size  limit       split  \\\n",
       "0                2048              4096          32   1000  validation   \n",
       "1                2048              4096          32   1000  validation   \n",
       "2                2048              4096          32   1000  validation   \n",
       "3                2048              4096          32   1000  validation   \n",
       "4                2048             20480          32   1000  validation   \n",
       "..                ...               ...         ...    ...         ...   \n",
       "353              2048              4096          32   1000  validation   \n",
       "354              2048              4096          32   1000  validation   \n",
       "355              2048              4096          32   1000  validation   \n",
       "356              2048             20480          32   1000  validation   \n",
       "357              2048             20480          32   1000  validation   \n",
       "\n",
       "     random_subsample_seed  num_shots unconditioned_prompt  \\\n",
       "0                     1234          0              Answer:   \n",
       "1                     1234          0              Answer:   \n",
       "2                     1234          0              Answer:   \n",
       "3                     1234          0              Answer:   \n",
       "4                     1234          0              Answer:   \n",
       "..                     ...        ...                  ...   \n",
       "353                   1234          0                        \n",
       "354                   1234          0              Answer:   \n",
       "355                   1234          0              Answer:   \n",
       "356                   1234          0              Answer:   \n",
       "357                   1234          0              Answer:   \n",
       "\n",
       "                                           all_metrics  \\\n",
       "0    {\"acc_raw\": 0.465, \"predicted_indices_raw\": [[...   \n",
       "1    {\"acc_raw\": 0.587, \"predicted_indices_raw\": [[...   \n",
       "2    {\"acc_raw\": 0.469, \"predicted_indices_raw\": [[...   \n",
       "3    {\"acc_raw\": 0.589, \"predicted_indices_raw\": [[...   \n",
       "4    {\"acc_raw\": 0.21070234113712374, \"predicted_in...   \n",
       "..                                                 ...   \n",
       "353  {\"acc_raw\": 0.375, \"predicted_indices_raw\": [[...   \n",
       "354  {\"acc_raw\": 0.457, \"predicted_indices_raw\": [[...   \n",
       "355  {\"acc_raw\": 0.564, \"predicted_indices_raw\": [[...   \n",
       "356  {\"acc_raw\": 0.21070234113712374, \"predicted_in...   \n",
       "357  {\"acc_raw\": 0.4649122807017544, \"predicted_ind...   \n",
       "\n",
       "                      beaker_id  \n",
       "0    01HKP9VR07QZZ8HCJM1NP4QV96  \n",
       "1    01HKP9VR07QZZ8HCJM1NP4QV96  \n",
       "2    01HKP9VJ3VAERXS3X91X12RS42  \n",
       "3    01HKP9VJ3VAERXS3X91X12RS42  \n",
       "4    01HKQC8C9J6GSJTZ36GR3D5QBD  \n",
       "..                          ...  \n",
       "353  01HKS6YZAHS5EY2RC43FBSZ07F  \n",
       "354  01HKSW4Y5X6R5VJ6ZPZ6HSJQFR  \n",
       "355  01HKSW4Y5X6R5VJ6ZPZ6HSJQFR  \n",
       "356  01HMT2Y51AZECJQ7J996GCTFBE  \n",
       "357  01HMT2Y51AZECJQ7J996GCTFBE  \n",
       "\n",
       "[358 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5153fc6f-b008-4756-8100-ac8865b03ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# # Sample data\n",
    "# data = np.random.rand(10, 5)  # 10x5 matrix of random numbers between 0 and 1\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Use the built-in \"PiYG\" colormap\n",
    "cmap = plt.colormaps.get_cmap('PiYG')\n",
    "\n",
    "# Function to blend color with white\n",
    "def blend_with_white(color, factor=0.5):\n",
    "    # Blending with white can be done by averaging the color with white\n",
    "    white = np.array([1, 1, 1, 1])\n",
    "    return white * factor + np.array(color) * (1 - factor)\n",
    "\n",
    "# Adjust the colormap\n",
    "new_colors = [blend_with_white(cmap(i), 0.3) for i in range(cmap.N)]\n",
    "new_cmap = mcolors.LinearSegmentedColormap.from_list(\"adjusted_PiYG\", new_colors, N=cmap.N)\n",
    "\n",
    "# If taking value from 0 to 1\n",
    "# # Function to apply the color mapping\n",
    "# def colorize(val):\n",
    "#     color = new_cmap(val)\n",
    "#     return f'background-color: {matplotlib.colors.rgb2hex(color)}'\n",
    "\n",
    "# Function to apply the color mapping\n",
    "# If taking value from 0 to 100\n",
    "def colorize(val):\n",
    "    # Normalize the value to the range [0, 1]\n",
    "    normalized_val = float(val) / 100 if val != \"NA\" else 0.0\n",
    "    color = new_cmap(normalized_val)\n",
    "    return f'background-color: {matplotlib.colors.rgb2hex(color)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5aa2035-f57f-4ed6-b2fa-fc20d2d4662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiiuae/falcon-rw-7b', 'llama2-7b', 'HuggingFaceH4/zephyr-7b-beta', 'llama-7b', 'Salesforce/xgen-7b-4k-base', 'tiiuae/falcon-7b', 'mosaicml/mpt-7b-instruct', 'mosaicml/mpt-7b', 'Salesforce/xgen-7b-8k-inst', 'olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf']\n",
      "['arc_challenge', 'arc_easy', 'boolq', 'copa', 'headqa_en', 'hellaswag', 'logiqa', 'mathqa', 'mrpc', 'openbookqa', 'piqa', 'qnli', 'qqp', 'rte', 'sciq', 'sst', 'wic', 'winogrande', 'wnli', 'wsc', 'social_iqa', 'csqa']\n"
     ]
    }
   ],
   "source": [
    "# Define the subset of models and tasks you want to display\n",
    "models_to_plot = []\n",
    "for model_name in set(all_res['model']):\n",
    "    if \"olmo\" not in model_name and \"7b\" in model_name: # e.g., focus on 7B models\n",
    "        models_to_plot.append(model_name)\n",
    "models_to_plot += [\"olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf\"]\n",
    "# models_to_plot = [('metric', item.capitalize()) for item in models_to_plot] # match models_by_task.columns format\n",
    "print(models_to_plot)\n",
    "\n",
    "tasks_to_plot = TASK_SPECS[\"rc_plus_n0_val1000\"][\"task\"].split() # e.g., focus on the 20 tasks\n",
    "print(tasks_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d02aad3-c539-4c3f-a472-1c1ec706e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_model_name_res = all_res.copy()\n",
    "# Filter the DataFrame to include only the selected models and tasks\n",
    "processed_model_name_res = processed_model_name_res[processed_model_name_res['model'].isin(models_to_plot) & processed_model_name_res['task'].isin(tasks_to_plot)]\n",
    "\n",
    "def get_model_name_with_revision(row):\n",
    "    # Split the \"model\" names at \"/\", take whatever is after it, and capitalize the \"model\" names\n",
    "    model_name = row['model'].split(\"/\")[-1].capitalize()\n",
    "    # Extract and concatenate the revision if it exists\n",
    "    model_kwargs = eval(row['model_kwargs'])  # 'model_kwargs' is a string representation of a dictionary\n",
    "    revision = model_kwargs.get('revision')\n",
    "    if revision is not None:\n",
    "        model_name += f\"-{revision}\"\n",
    "    return model_name\n",
    "\n",
    "# Apply the process model name function to each row of the DataFrame\n",
    "processed_model_name_res['model'] = processed_model_name_res.apply(get_model_name_with_revision, axis=1)\n",
    "# Remove duplicate models and task eval, keeping the first instance of each set of such cases\n",
    "all_res_dedup = processed_model_name_res[~processed_model_name_res.duplicated(subset=['full_model', 'model_kwargs', 'task', 'metric'], keep='first')]\n",
    "\n",
    "# Rows - task, Columns - model\n",
    "models_by_task = all_res_dedup.loc[:,['model', 'task', 'metric']].groupby(['task', 'model']).sum().unstack('model')\n",
    "\n",
    "# Move Olmo model columns to be behind\n",
    "word_to_move = \"Olmo\"\n",
    "# Create a boolean mask that is True for columns starting the word\n",
    "mask = models_by_task.columns.get_level_values(1).str.startswith(word_to_move)\n",
    "# Select columns that do NOT contain the word, followed by columns that DO contain it\n",
    "cols_without_word = models_by_task.columns[~mask]\n",
    "cols_with_word = models_by_task.columns[mask]\n",
    "# Combine the columns in the desired order and reindex the DataFrame\n",
    "new_column_order = cols_without_word.tolist() + cols_with_word.tolist()\n",
    "models_by_task = models_by_task.reindex(columns=new_column_order)\n",
    "\n",
    "# Map to 0 to 100\n",
    "models_by_task = models_by_task.apply(pd.to_numeric, errors='coerce')\n",
    "models_by_task = models_by_task.apply(lambda x: x.map(lambda y: '{:.2f}'.format(y*100) if pd.notnull(y) else '{:.2f}'.format(0.0)))\n",
    "\n",
    "# Remove the top header row that says \"metric\"\n",
    "models_by_task.columns = models_by_task.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c274bbe3-2dfd-4529-a249-5962b91bdf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>Falcon-7b</th>\n",
       "      <th>Falcon-rw-7b</th>\n",
       "      <th>Llama-7b</th>\n",
       "      <th>Llama2-7b</th>\n",
       "      <th>Mpt-7b</th>\n",
       "      <th>Mpt-7b-instruct</th>\n",
       "      <th>Xgen-7b-4k-base</th>\n",
       "      <th>Xgen-7b-8k-inst</th>\n",
       "      <th>Zephyr-7b-beta</th>\n",
       "      <th>Olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arc_challenge</th>\n",
       "      <td>47.49</td>\n",
       "      <td>43.14</td>\n",
       "      <td>44.48</td>\n",
       "      <td>48.49</td>\n",
       "      <td>46.49</td>\n",
       "      <td>46.15</td>\n",
       "      <td>45.82</td>\n",
       "      <td>47.83</td>\n",
       "      <td>57.86</td>\n",
       "      <td>48.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arc_easy</th>\n",
       "      <td>70.35</td>\n",
       "      <td>65.09</td>\n",
       "      <td>67.89</td>\n",
       "      <td>69.47</td>\n",
       "      <td>70.53</td>\n",
       "      <td>70.00</td>\n",
       "      <td>67.02</td>\n",
       "      <td>67.72</td>\n",
       "      <td>79.65</td>\n",
       "      <td>65.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boolq</th>\n",
       "      <td>74.60</td>\n",
       "      <td>70.20</td>\n",
       "      <td>75.40</td>\n",
       "      <td>80.20</td>\n",
       "      <td>74.20</td>\n",
       "      <td>73.40</td>\n",
       "      <td>73.60</td>\n",
       "      <td>77.40</td>\n",
       "      <td>86.60</td>\n",
       "      <td>73.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>copa</th>\n",
       "      <td>86.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>88.00</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csqa</th>\n",
       "      <td>64.60</td>\n",
       "      <td>61.20</td>\n",
       "      <td>62.60</td>\n",
       "      <td>62.90</td>\n",
       "      <td>63.40</td>\n",
       "      <td>65.80</td>\n",
       "      <td>59.30</td>\n",
       "      <td>59.80</td>\n",
       "      <td>62.20</td>\n",
       "      <td>61.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headqa_en</th>\n",
       "      <td>38.60</td>\n",
       "      <td>36.50</td>\n",
       "      <td>38.70</td>\n",
       "      <td>39.50</td>\n",
       "      <td>37.40</td>\n",
       "      <td>38.30</td>\n",
       "      <td>40.80</td>\n",
       "      <td>38.90</td>\n",
       "      <td>47.20</td>\n",
       "      <td>37.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellaswag</th>\n",
       "      <td>75.90</td>\n",
       "      <td>73.30</td>\n",
       "      <td>76.20</td>\n",
       "      <td>76.80</td>\n",
       "      <td>77.60</td>\n",
       "      <td>77.50</td>\n",
       "      <td>67.20</td>\n",
       "      <td>76.20</td>\n",
       "      <td>82.10</td>\n",
       "      <td>76.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logiqa</th>\n",
       "      <td>23.66</td>\n",
       "      <td>21.81</td>\n",
       "      <td>19.51</td>\n",
       "      <td>26.11</td>\n",
       "      <td>22.89</td>\n",
       "      <td>23.50</td>\n",
       "      <td>22.89</td>\n",
       "      <td>24.88</td>\n",
       "      <td>32.57</td>\n",
       "      <td>23.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mathqa</th>\n",
       "      <td>30.00</td>\n",
       "      <td>27.50</td>\n",
       "      <td>30.20</td>\n",
       "      <td>31.60</td>\n",
       "      <td>28.90</td>\n",
       "      <td>28.90</td>\n",
       "      <td>27.80</td>\n",
       "      <td>28.60</td>\n",
       "      <td>40.00</td>\n",
       "      <td>26.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrpc</th>\n",
       "      <td>62.75</td>\n",
       "      <td>39.95</td>\n",
       "      <td>68.63</td>\n",
       "      <td>69.12</td>\n",
       "      <td>67.65</td>\n",
       "      <td>68.14</td>\n",
       "      <td>52.70</td>\n",
       "      <td>41.67</td>\n",
       "      <td>71.81</td>\n",
       "      <td>68.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openbookqa</th>\n",
       "      <td>53.00</td>\n",
       "      <td>47.80</td>\n",
       "      <td>51.20</td>\n",
       "      <td>48.40</td>\n",
       "      <td>48.60</td>\n",
       "      <td>47.60</td>\n",
       "      <td>46.40</td>\n",
       "      <td>44.80</td>\n",
       "      <td>49.80</td>\n",
       "      <td>50.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piqa</th>\n",
       "      <td>78.50</td>\n",
       "      <td>77.90</td>\n",
       "      <td>77.20</td>\n",
       "      <td>76.70</td>\n",
       "      <td>77.30</td>\n",
       "      <td>77.20</td>\n",
       "      <td>74.50</td>\n",
       "      <td>74.70</td>\n",
       "      <td>80.50</td>\n",
       "      <td>78.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qnli</th>\n",
       "      <td>49.80</td>\n",
       "      <td>49.90</td>\n",
       "      <td>50.10</td>\n",
       "      <td>49.40</td>\n",
       "      <td>52.10</td>\n",
       "      <td>49.30</td>\n",
       "      <td>50.00</td>\n",
       "      <td>49.40</td>\n",
       "      <td>51.30</td>\n",
       "      <td>49.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qqp</th>\n",
       "      <td>40.70</td>\n",
       "      <td>37.50</td>\n",
       "      <td>41.30</td>\n",
       "      <td>38.30</td>\n",
       "      <td>47.50</td>\n",
       "      <td>38.20</td>\n",
       "      <td>39.00</td>\n",
       "      <td>62.40</td>\n",
       "      <td>75.50</td>\n",
       "      <td>40.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rte</th>\n",
       "      <td>61.73</td>\n",
       "      <td>52.71</td>\n",
       "      <td>66.43</td>\n",
       "      <td>62.82</td>\n",
       "      <td>62.82</td>\n",
       "      <td>69.68</td>\n",
       "      <td>57.76</td>\n",
       "      <td>63.54</td>\n",
       "      <td>74.01</td>\n",
       "      <td>51.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sciq</th>\n",
       "      <td>93.90</td>\n",
       "      <td>93.60</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.50</td>\n",
       "      <td>93.70</td>\n",
       "      <td>94.20</td>\n",
       "      <td>92.60</td>\n",
       "      <td>92.90</td>\n",
       "      <td>96.20</td>\n",
       "      <td>93.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social_iqa</th>\n",
       "      <td>49.20</td>\n",
       "      <td>44.60</td>\n",
       "      <td>48.90</td>\n",
       "      <td>48.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>49.00</td>\n",
       "      <td>45.30</td>\n",
       "      <td>49.00</td>\n",
       "      <td>51.40</td>\n",
       "      <td>46.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst</th>\n",
       "      <td>49.08</td>\n",
       "      <td>48.51</td>\n",
       "      <td>83.26</td>\n",
       "      <td>51.95</td>\n",
       "      <td>75.80</td>\n",
       "      <td>87.27</td>\n",
       "      <td>55.96</td>\n",
       "      <td>64.45</td>\n",
       "      <td>88.30</td>\n",
       "      <td>60.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wic</th>\n",
       "      <td>49.53</td>\n",
       "      <td>49.53</td>\n",
       "      <td>49.06</td>\n",
       "      <td>49.84</td>\n",
       "      <td>48.12</td>\n",
       "      <td>48.28</td>\n",
       "      <td>48.59</td>\n",
       "      <td>53.92</td>\n",
       "      <td>61.44</td>\n",
       "      <td>50.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winogrande</th>\n",
       "      <td>68.90</td>\n",
       "      <td>67.00</td>\n",
       "      <td>70.50</td>\n",
       "      <td>69.40</td>\n",
       "      <td>69.90</td>\n",
       "      <td>69.10</td>\n",
       "      <td>68.30</td>\n",
       "      <td>66.60</td>\n",
       "      <td>73.40</td>\n",
       "      <td>67.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnli</th>\n",
       "      <td>47.89</td>\n",
       "      <td>52.11</td>\n",
       "      <td>52.11</td>\n",
       "      <td>45.07</td>\n",
       "      <td>47.89</td>\n",
       "      <td>42.25</td>\n",
       "      <td>52.11</td>\n",
       "      <td>43.66</td>\n",
       "      <td>63.38</td>\n",
       "      <td>56.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc</th>\n",
       "      <td>35.58</td>\n",
       "      <td>59.62</td>\n",
       "      <td>50.96</td>\n",
       "      <td>36.54</td>\n",
       "      <td>63.46</td>\n",
       "      <td>64.42</td>\n",
       "      <td>36.54</td>\n",
       "      <td>36.54</td>\n",
       "      <td>63.46</td>\n",
       "      <td>37.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model         Falcon-7b Falcon-rw-7b Llama-7b Llama2-7b Mpt-7b  \\\n",
       "task                                                             \n",
       "arc_challenge     47.49        43.14    44.48     48.49  46.49   \n",
       "arc_easy          70.35        65.09    67.89     69.47  70.53   \n",
       "boolq             74.60        70.20    75.40     80.20  74.20   \n",
       "copa              86.00        87.00    91.00     86.00  85.00   \n",
       "csqa              64.60        61.20    62.60     62.90  63.40   \n",
       "headqa_en         38.60        36.50    38.70     39.50  37.40   \n",
       "hellaswag         75.90        73.30    76.20     76.80  77.60   \n",
       "logiqa            23.66        21.81    19.51     26.11  22.89   \n",
       "mathqa            30.00        27.50    30.20     31.60  28.90   \n",
       "mrpc              62.75        39.95    68.63     69.12  67.65   \n",
       "openbookqa        53.00        47.80    51.20     48.40  48.60   \n",
       "piqa              78.50        77.90    77.20     76.70  77.30   \n",
       "qnli              49.80        49.90    50.10     49.40  52.10   \n",
       "qqp               40.70        37.50    41.30     38.30  47.50   \n",
       "rte               61.73        52.71    66.43     62.82  62.82   \n",
       "sciq              93.90        93.60    93.90     94.50  93.70   \n",
       "social_iqa        49.20        44.60    48.90     48.00  47.40   \n",
       "sst               49.08        48.51    83.26     51.95  75.80   \n",
       "wic               49.53        49.53    49.06     49.84  48.12   \n",
       "winogrande        68.90        67.00    70.50     69.40  69.90   \n",
       "wnli              47.89        52.11    52.11     45.07  47.89   \n",
       "wsc               35.58        59.62    50.96     36.54  63.46   \n",
       "\n",
       "model         Mpt-7b-instruct Xgen-7b-4k-base Xgen-7b-8k-inst Zephyr-7b-beta  \\\n",
       "task                                                                           \n",
       "arc_challenge           46.15           45.82           47.83          57.86   \n",
       "arc_easy                70.00           67.02           67.72          79.65   \n",
       "boolq                   73.40           73.60           77.40          86.60   \n",
       "copa                    90.00           80.00           80.00          88.00   \n",
       "csqa                    65.80           59.30           59.80          62.20   \n",
       "headqa_en               38.30           40.80           38.90          47.20   \n",
       "hellaswag               77.50           67.20           76.20          82.10   \n",
       "logiqa                  23.50           22.89           24.88          32.57   \n",
       "mathqa                  28.90           27.80           28.60          40.00   \n",
       "mrpc                    68.14           52.70           41.67          71.81   \n",
       "openbookqa              47.60           46.40           44.80          49.80   \n",
       "piqa                    77.20           74.50           74.70          80.50   \n",
       "qnli                    49.30           50.00           49.40          51.30   \n",
       "qqp                     38.20           39.00           62.40          75.50   \n",
       "rte                     69.68           57.76           63.54          74.01   \n",
       "sciq                    94.20           92.60           92.90          96.20   \n",
       "social_iqa              49.00           45.30           49.00          51.40   \n",
       "sst                     87.27           55.96           64.45          88.30   \n",
       "wic                     48.28           48.59           53.92          61.44   \n",
       "winogrande              69.10           68.30           66.60          73.40   \n",
       "wnli                    42.25           52.11           43.66          63.38   \n",
       "wsc                     64.42           36.54           36.54          63.46   \n",
       "\n",
       "model         Olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf  \n",
       "task                                                           \n",
       "arc_challenge                                           48.49  \n",
       "arc_easy                                                65.44  \n",
       "boolq                                                   73.40  \n",
       "copa                                                    90.00  \n",
       "csqa                                                    61.80  \n",
       "headqa_en                                               37.30  \n",
       "hellaswag                                               76.40  \n",
       "logiqa                                                  23.35  \n",
       "mathqa                                                  26.60  \n",
       "mrpc                                                    68.38  \n",
       "openbookqa                                              50.40  \n",
       "piqa                                                    78.40  \n",
       "qnli                                                    49.10  \n",
       "qqp                                                     40.60  \n",
       "rte                                                     51.99  \n",
       "sciq                                                    93.80  \n",
       "social_iqa                                              46.50  \n",
       "sst                                                     60.44  \n",
       "wic                                                     50.16  \n",
       "winogrande                                              67.90  \n",
       "wnli                                                    56.34  \n",
       "wsc                                                     37.50  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_by_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23c77742-a42c-4732-8119-6c4c0951d532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_62a09_row0_col0, #T_62a09_row10_col5, #T_62a09_row13_col4, #T_62a09_row16_col4 {\n",
       "  background-color: #faf5f8;\n",
       "}\n",
       "#T_62a09_row0_col1 {\n",
       "  background-color: #fceef6;\n",
       "}\n",
       "#T_62a09_row0_col2 {\n",
       "  background-color: #fcf0f6;\n",
       "}\n",
       "#T_62a09_row0_col3, #T_62a09_row0_col9, #T_62a09_row10_col4, #T_62a09_row17_col1, #T_62a09_row18_col6 {\n",
       "  background-color: #faf7f9;\n",
       "}\n",
       "#T_62a09_row0_col4, #T_62a09_row16_col9 {\n",
       "  background-color: #fbf4f8;\n",
       "}\n",
       "#T_62a09_row0_col5, #T_62a09_row0_col6, #T_62a09_row10_col6 {\n",
       "  background-color: #fbf3f7;\n",
       "}\n",
       "#T_62a09_row0_col7, #T_62a09_row10_col1, #T_62a09_row16_col3, #T_62a09_row20_col0, #T_62a09_row20_col4 {\n",
       "  background-color: #faf6f8;\n",
       "}\n",
       "#T_62a09_row0_col8 {\n",
       "  background-color: #f0f8e3;\n",
       "}\n",
       "#T_62a09_row1_col0, #T_62a09_row1_col4, #T_62a09_row19_col2 {\n",
       "  background-color: #cbe8a7;\n",
       "}\n",
       "#T_62a09_row1_col1 {\n",
       "  background-color: #ddf1c4;\n",
       "}\n",
       "#T_62a09_row1_col2, #T_62a09_row1_col7, #T_62a09_row9_col4, #T_62a09_row19_col9 {\n",
       "  background-color: #d4edb5;\n",
       "}\n",
       "#T_62a09_row1_col3, #T_62a09_row19_col3 {\n",
       "  background-color: #cfebad;\n",
       "}\n",
       "#T_62a09_row1_col5, #T_62a09_row2_col1 {\n",
       "  background-color: #cde9a9;\n",
       "}\n",
       "#T_62a09_row1_col6, #T_62a09_row19_col1 {\n",
       "  background-color: #d7eeba;\n",
       "}\n",
       "#T_62a09_row1_col8 {\n",
       "  background-color: #a7d17c;\n",
       "}\n",
       "#T_62a09_row1_col9 {\n",
       "  background-color: #dcf0c2;\n",
       "}\n",
       "#T_62a09_row2_col0, #T_62a09_row11_col6 {\n",
       "  background-color: #bbde95;\n",
       "}\n",
       "#T_62a09_row2_col2, #T_62a09_row13_col8 {\n",
       "  background-color: #b7db8f;\n",
       "}\n",
       "#T_62a09_row2_col3 {\n",
       "  background-color: #a4cf79;\n",
       "}\n",
       "#T_62a09_row2_col4, #T_62a09_row14_col8 {\n",
       "  background-color: #bddf96;\n",
       "}\n",
       "#T_62a09_row2_col5, #T_62a09_row2_col9, #T_62a09_row6_col1, #T_62a09_row19_col8 {\n",
       "  background-color: #c0e19a;\n",
       "}\n",
       "#T_62a09_row2_col6 {\n",
       "  background-color: #bee098;\n",
       "}\n",
       "#T_62a09_row2_col7, #T_62a09_row6_col4, #T_62a09_row6_col5 {\n",
       "  background-color: #afd685;\n",
       "}\n",
       "#T_62a09_row2_col8 {\n",
       "  background-color: #8ebc6b;\n",
       "}\n",
       "#T_62a09_row3_col0, #T_62a09_row3_col3 {\n",
       "  background-color: #8fbe6c;\n",
       "}\n",
       "#T_62a09_row3_col1 {\n",
       "  background-color: #8dbb6a;\n",
       "}\n",
       "#T_62a09_row3_col2 {\n",
       "  background-color: #80b063;\n",
       "}\n",
       "#T_62a09_row3_col4 {\n",
       "  background-color: #94c16f;\n",
       "}\n",
       "#T_62a09_row3_col5, #T_62a09_row3_col9 {\n",
       "  background-color: #82b263;\n",
       "}\n",
       "#T_62a09_row3_col6, #T_62a09_row3_col7 {\n",
       "  background-color: #a5d07a;\n",
       "}\n",
       "#T_62a09_row3_col8 {\n",
       "  background-color: #89b868;\n",
       "}\n",
       "#T_62a09_row4_col0 {\n",
       "  background-color: #def1c6;\n",
       "}\n",
       "#T_62a09_row4_col1 {\n",
       "  background-color: #eaf6d8;\n",
       "}\n",
       "#T_62a09_row4_col2, #T_62a09_row9_col0, #T_62a09_row14_col3, #T_62a09_row14_col4 {\n",
       "  background-color: #e5f4d0;\n",
       "}\n",
       "#T_62a09_row4_col3 {\n",
       "  background-color: #e3f4ce;\n",
       "}\n",
       "#T_62a09_row4_col4, #T_62a09_row14_col7, #T_62a09_row20_col8, #T_62a09_row21_col4, #T_62a09_row21_col8 {\n",
       "  background-color: #e2f3cc;\n",
       "}\n",
       "#T_62a09_row4_col5 {\n",
       "  background-color: #dbf0c0;\n",
       "}\n",
       "#T_62a09_row4_col6 {\n",
       "  background-color: #eef8e0;\n",
       "}\n",
       "#T_62a09_row4_col7 {\n",
       "  background-color: #eef8de;\n",
       "}\n",
       "#T_62a09_row4_col8, #T_62a09_row13_col7 {\n",
       "  background-color: #e6f5d2;\n",
       "}\n",
       "#T_62a09_row4_col9, #T_62a09_row14_col0 {\n",
       "  background-color: #e7f5d4;\n",
       "}\n",
       "#T_62a09_row5_col0, #T_62a09_row5_col5, #T_62a09_row13_col3 {\n",
       "  background-color: #fce5f1;\n",
       "}\n",
       "#T_62a09_row5_col1, #T_62a09_row21_col3, #T_62a09_row21_col6, #T_62a09_row21_col7 {\n",
       "  background-color: #fbdfef;\n",
       "}\n",
       "#T_62a09_row5_col2, #T_62a09_row5_col7, #T_62a09_row13_col6 {\n",
       "  background-color: #fde6f2;\n",
       "}\n",
       "#T_62a09_row5_col3 {\n",
       "  background-color: #fde8f3;\n",
       "}\n",
       "#T_62a09_row5_col4, #T_62a09_row5_col9 {\n",
       "  background-color: #fbe1f0;\n",
       "}\n",
       "#T_62a09_row5_col6, #T_62a09_row13_col0, #T_62a09_row13_col2 {\n",
       "  background-color: #fdebf4;\n",
       "}\n",
       "#T_62a09_row5_col8 {\n",
       "  background-color: #fbf5f8;\n",
       "}\n",
       "#T_62a09_row6_col0, #T_62a09_row17_col4 {\n",
       "  background-color: #b5da8d;\n",
       "}\n",
       "#T_62a09_row6_col2, #T_62a09_row6_col7, #T_62a09_row6_col9 {\n",
       "  background-color: #b3d98b;\n",
       "}\n",
       "#T_62a09_row6_col3, #T_62a09_row11_col3 {\n",
       "  background-color: #b2d889;\n",
       "}\n",
       "#T_62a09_row6_col6 {\n",
       "  background-color: #d6eeb8;\n",
       "}\n",
       "#T_62a09_row6_col8 {\n",
       "  background-color: #9dc975;\n",
       "}\n",
       "#T_62a09_row7_col0, #T_62a09_row7_col5 {\n",
       "  background-color: #edafd1;\n",
       "}\n",
       "#T_62a09_row7_col1 {\n",
       "  background-color: #eaa7cb;\n",
       "}\n",
       "#T_62a09_row7_col2 {\n",
       "  background-color: #e79bc4;\n",
       "}\n",
       "#T_62a09_row7_col3 {\n",
       "  background-color: #f0bad8;\n",
       "}\n",
       "#T_62a09_row7_col4, #T_62a09_row7_col6 {\n",
       "  background-color: #ecaccf;\n",
       "}\n",
       "#T_62a09_row7_col7 {\n",
       "  background-color: #eeb5d5;\n",
       "}\n",
       "#T_62a09_row7_col8 {\n",
       "  background-color: #f7d3e9;\n",
       "}\n",
       "#T_62a09_row7_col9 {\n",
       "  background-color: #ecaed0;\n",
       "}\n",
       "#T_62a09_row8_col0 {\n",
       "  background-color: #f5cbe4;\n",
       "}\n",
       "#T_62a09_row8_col1 {\n",
       "  background-color: #f2c1dd;\n",
       "}\n",
       "#T_62a09_row8_col2 {\n",
       "  background-color: #f5cce5;\n",
       "}\n",
       "#T_62a09_row8_col3 {\n",
       "  background-color: #f6d0e7;\n",
       "}\n",
       "#T_62a09_row8_col4, #T_62a09_row8_col5, #T_62a09_row8_col7 {\n",
       "  background-color: #f3c6e1;\n",
       "}\n",
       "#T_62a09_row8_col6 {\n",
       "  background-color: #f2c2de;\n",
       "}\n",
       "#T_62a09_row8_col8, #T_62a09_row9_col1 {\n",
       "  background-color: #fee9f4;\n",
       "}\n",
       "#T_62a09_row8_col9 {\n",
       "  background-color: #f1bddb;\n",
       "}\n",
       "#T_62a09_row9_col2, #T_62a09_row9_col9 {\n",
       "  background-color: #d2ecb1;\n",
       "}\n",
       "#T_62a09_row9_col3, #T_62a09_row19_col0, #T_62a09_row19_col5 {\n",
       "  background-color: #d0ebaf;\n",
       "}\n",
       "#T_62a09_row9_col5, #T_62a09_row19_col6 {\n",
       "  background-color: #d3ecb3;\n",
       "}\n",
       "#T_62a09_row9_col6, #T_62a09_row14_col1 {\n",
       "  background-color: #f6f9f2;\n",
       "}\n",
       "#T_62a09_row9_col7 {\n",
       "  background-color: #fdecf5;\n",
       "}\n",
       "#T_62a09_row9_col8 {\n",
       "  background-color: #c6e5a2;\n",
       "}\n",
       "#T_62a09_row10_col0 {\n",
       "  background-color: #f6f9f1;\n",
       "}\n",
       "#T_62a09_row10_col2, #T_62a09_row12_col8, #T_62a09_row16_col8 {\n",
       "  background-color: #f8f9f6;\n",
       "}\n",
       "#T_62a09_row10_col3, #T_62a09_row18_col4, #T_62a09_row18_col5 {\n",
       "  background-color: #faf7f8;\n",
       "}\n",
       "#T_62a09_row10_col7, #T_62a09_row16_col1 {\n",
       "  background-color: #fcf1f6;\n",
       "}\n",
       "#T_62a09_row10_col8, #T_62a09_row12_col0, #T_62a09_row12_col1, #T_62a09_row12_col2, #T_62a09_row12_col6, #T_62a09_row18_col3, #T_62a09_row18_col9 {\n",
       "  background-color: #f9f9f9;\n",
       "}\n",
       "#T_62a09_row10_col9 {\n",
       "  background-color: #f9f9f8;\n",
       "}\n",
       "#T_62a09_row11_col0, #T_62a09_row11_col9 {\n",
       "  background-color: #acd482;\n",
       "}\n",
       "#T_62a09_row11_col1 {\n",
       "  background-color: #add583;\n",
       "}\n",
       "#T_62a09_row11_col2, #T_62a09_row11_col4, #T_62a09_row11_col5 {\n",
       "  background-color: #b0d787;\n",
       "}\n",
       "#T_62a09_row11_col7 {\n",
       "  background-color: #badd93;\n",
       "}\n",
       "#T_62a09_row11_col8 {\n",
       "  background-color: #a3ce78;\n",
       "}\n",
       "#T_62a09_row12_col3, #T_62a09_row12_col5, #T_62a09_row12_col7, #T_62a09_row12_col9, #T_62a09_row16_col0, #T_62a09_row16_col2, #T_62a09_row16_col5, #T_62a09_row16_col7, #T_62a09_row17_col0, #T_62a09_row18_col0, #T_62a09_row18_col1, #T_62a09_row18_col2 {\n",
       "  background-color: #faf8f9;\n",
       "}\n",
       "#T_62a09_row12_col4, #T_62a09_row14_col9, #T_62a09_row20_col1, #T_62a09_row20_col2, #T_62a09_row20_col6 {\n",
       "  background-color: #f7f9f4;\n",
       "}\n",
       "#T_62a09_row13_col1, #T_62a09_row21_col9 {\n",
       "  background-color: #fce2f0;\n",
       "}\n",
       "#T_62a09_row13_col5 {\n",
       "  background-color: #fce4f1;\n",
       "}\n",
       "#T_62a09_row13_col9 {\n",
       "  background-color: #fdeaf4;\n",
       "}\n",
       "#T_62a09_row14_col2, #T_62a09_row19_col7 {\n",
       "  background-color: #d8efbc;\n",
       "}\n",
       "#T_62a09_row14_col5, #T_62a09_row19_col4 {\n",
       "  background-color: #ceeaab;\n",
       "}\n",
       "#T_62a09_row14_col6 {\n",
       "  background-color: #f0f8e5;\n",
       "}\n",
       "#T_62a09_row15_col0, #T_62a09_row15_col2, #T_62a09_row15_col9 {\n",
       "  background-color: #77a561;\n",
       "}\n",
       "#T_62a09_row15_col1, #T_62a09_row15_col4 {\n",
       "  background-color: #78a762;\n",
       "}\n",
       "#T_62a09_row15_col3, #T_62a09_row15_col5 {\n",
       "  background-color: #76a461;\n",
       "}\n",
       "#T_62a09_row15_col6, #T_62a09_row15_col7 {\n",
       "  background-color: #7ba962;\n",
       "}\n",
       "#T_62a09_row15_col8 {\n",
       "  background-color: #719e60;\n",
       "}\n",
       "#T_62a09_row16_col6, #T_62a09_row20_col3 {\n",
       "  background-color: #fbf2f7;\n",
       "}\n",
       "#T_62a09_row17_col2 {\n",
       "  background-color: #99c672;\n",
       "}\n",
       "#T_62a09_row17_col3 {\n",
       "  background-color: #f7f9f5;\n",
       "}\n",
       "#T_62a09_row17_col5 {\n",
       "  background-color: #8bba69;\n",
       "}\n",
       "#T_62a09_row17_col6 {\n",
       "  background-color: #f2f9e9;\n",
       "}\n",
       "#T_62a09_row17_col7, #T_62a09_row21_col5 {\n",
       "  background-color: #e0f2c8;\n",
       "}\n",
       "#T_62a09_row17_col8 {\n",
       "  background-color: #87b767;\n",
       "}\n",
       "#T_62a09_row17_col9 {\n",
       "  background-color: #ecf7dc;\n",
       "}\n",
       "#T_62a09_row18_col7 {\n",
       "  background-color: #f4f9ee;\n",
       "}\n",
       "#T_62a09_row18_col8 {\n",
       "  background-color: #e8f6d6;\n",
       "}\n",
       "#T_62a09_row20_col5 {\n",
       "  background-color: #fdedf5;\n",
       "}\n",
       "#T_62a09_row20_col7 {\n",
       "  background-color: #fceff6;\n",
       "}\n",
       "#T_62a09_row20_col9 {\n",
       "  background-color: #f2f8e8;\n",
       "}\n",
       "#T_62a09_row21_col0 {\n",
       "  background-color: #fadded;\n",
       "}\n",
       "#T_62a09_row21_col1 {\n",
       "  background-color: #eef8df;\n",
       "}\n",
       "#T_62a09_row21_col2 {\n",
       "  background-color: #f8f9f7;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_62a09\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_62a09_level0_col0\" class=\"col_heading level0 col0\" >Falcon-7b</th>\n",
       "      <th id=\"T_62a09_level0_col1\" class=\"col_heading level0 col1\" >Falcon-rw-7b</th>\n",
       "      <th id=\"T_62a09_level0_col2\" class=\"col_heading level0 col2\" >Llama-7b</th>\n",
       "      <th id=\"T_62a09_level0_col3\" class=\"col_heading level0 col3\" >Llama2-7b</th>\n",
       "      <th id=\"T_62a09_level0_col4\" class=\"col_heading level0 col4\" >Mpt-7b</th>\n",
       "      <th id=\"T_62a09_level0_col5\" class=\"col_heading level0 col5\" >Mpt-7b-instruct</th>\n",
       "      <th id=\"T_62a09_level0_col6\" class=\"col_heading level0 col6\" >Xgen-7b-4k-base</th>\n",
       "      <th id=\"T_62a09_level0_col7\" class=\"col_heading level0 col7\" >Xgen-7b-8k-inst</th>\n",
       "      <th id=\"T_62a09_level0_col8\" class=\"col_heading level0 col8\" >Zephyr-7b-beta</th>\n",
       "      <th id=\"T_62a09_level0_col9\" class=\"col_heading level0 col9\" >Olmo-7b-v1_5-mix-mitch-ish-mosaic-step557000-hf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row0\" class=\"row_heading level0 row0\" >arc_challenge</th>\n",
       "      <td id=\"T_62a09_row0_col0\" class=\"data row0 col0\" >47.49</td>\n",
       "      <td id=\"T_62a09_row0_col1\" class=\"data row0 col1\" >43.14</td>\n",
       "      <td id=\"T_62a09_row0_col2\" class=\"data row0 col2\" >44.48</td>\n",
       "      <td id=\"T_62a09_row0_col3\" class=\"data row0 col3\" >48.49</td>\n",
       "      <td id=\"T_62a09_row0_col4\" class=\"data row0 col4\" >46.49</td>\n",
       "      <td id=\"T_62a09_row0_col5\" class=\"data row0 col5\" >46.15</td>\n",
       "      <td id=\"T_62a09_row0_col6\" class=\"data row0 col6\" >45.82</td>\n",
       "      <td id=\"T_62a09_row0_col7\" class=\"data row0 col7\" >47.83</td>\n",
       "      <td id=\"T_62a09_row0_col8\" class=\"data row0 col8\" >57.86</td>\n",
       "      <td id=\"T_62a09_row0_col9\" class=\"data row0 col9\" >48.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row1\" class=\"row_heading level0 row1\" >arc_easy</th>\n",
       "      <td id=\"T_62a09_row1_col0\" class=\"data row1 col0\" >70.35</td>\n",
       "      <td id=\"T_62a09_row1_col1\" class=\"data row1 col1\" >65.09</td>\n",
       "      <td id=\"T_62a09_row1_col2\" class=\"data row1 col2\" >67.89</td>\n",
       "      <td id=\"T_62a09_row1_col3\" class=\"data row1 col3\" >69.47</td>\n",
       "      <td id=\"T_62a09_row1_col4\" class=\"data row1 col4\" >70.53</td>\n",
       "      <td id=\"T_62a09_row1_col5\" class=\"data row1 col5\" >70.00</td>\n",
       "      <td id=\"T_62a09_row1_col6\" class=\"data row1 col6\" >67.02</td>\n",
       "      <td id=\"T_62a09_row1_col7\" class=\"data row1 col7\" >67.72</td>\n",
       "      <td id=\"T_62a09_row1_col8\" class=\"data row1 col8\" >79.65</td>\n",
       "      <td id=\"T_62a09_row1_col9\" class=\"data row1 col9\" >65.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row2\" class=\"row_heading level0 row2\" >boolq</th>\n",
       "      <td id=\"T_62a09_row2_col0\" class=\"data row2 col0\" >74.60</td>\n",
       "      <td id=\"T_62a09_row2_col1\" class=\"data row2 col1\" >70.20</td>\n",
       "      <td id=\"T_62a09_row2_col2\" class=\"data row2 col2\" >75.40</td>\n",
       "      <td id=\"T_62a09_row2_col3\" class=\"data row2 col3\" >80.20</td>\n",
       "      <td id=\"T_62a09_row2_col4\" class=\"data row2 col4\" >74.20</td>\n",
       "      <td id=\"T_62a09_row2_col5\" class=\"data row2 col5\" >73.40</td>\n",
       "      <td id=\"T_62a09_row2_col6\" class=\"data row2 col6\" >73.60</td>\n",
       "      <td id=\"T_62a09_row2_col7\" class=\"data row2 col7\" >77.40</td>\n",
       "      <td id=\"T_62a09_row2_col8\" class=\"data row2 col8\" >86.60</td>\n",
       "      <td id=\"T_62a09_row2_col9\" class=\"data row2 col9\" >73.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row3\" class=\"row_heading level0 row3\" >copa</th>\n",
       "      <td id=\"T_62a09_row3_col0\" class=\"data row3 col0\" >86.00</td>\n",
       "      <td id=\"T_62a09_row3_col1\" class=\"data row3 col1\" >87.00</td>\n",
       "      <td id=\"T_62a09_row3_col2\" class=\"data row3 col2\" >91.00</td>\n",
       "      <td id=\"T_62a09_row3_col3\" class=\"data row3 col3\" >86.00</td>\n",
       "      <td id=\"T_62a09_row3_col4\" class=\"data row3 col4\" >85.00</td>\n",
       "      <td id=\"T_62a09_row3_col5\" class=\"data row3 col5\" >90.00</td>\n",
       "      <td id=\"T_62a09_row3_col6\" class=\"data row3 col6\" >80.00</td>\n",
       "      <td id=\"T_62a09_row3_col7\" class=\"data row3 col7\" >80.00</td>\n",
       "      <td id=\"T_62a09_row3_col8\" class=\"data row3 col8\" >88.00</td>\n",
       "      <td id=\"T_62a09_row3_col9\" class=\"data row3 col9\" >90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row4\" class=\"row_heading level0 row4\" >csqa</th>\n",
       "      <td id=\"T_62a09_row4_col0\" class=\"data row4 col0\" >64.60</td>\n",
       "      <td id=\"T_62a09_row4_col1\" class=\"data row4 col1\" >61.20</td>\n",
       "      <td id=\"T_62a09_row4_col2\" class=\"data row4 col2\" >62.60</td>\n",
       "      <td id=\"T_62a09_row4_col3\" class=\"data row4 col3\" >62.90</td>\n",
       "      <td id=\"T_62a09_row4_col4\" class=\"data row4 col4\" >63.40</td>\n",
       "      <td id=\"T_62a09_row4_col5\" class=\"data row4 col5\" >65.80</td>\n",
       "      <td id=\"T_62a09_row4_col6\" class=\"data row4 col6\" >59.30</td>\n",
       "      <td id=\"T_62a09_row4_col7\" class=\"data row4 col7\" >59.80</td>\n",
       "      <td id=\"T_62a09_row4_col8\" class=\"data row4 col8\" >62.20</td>\n",
       "      <td id=\"T_62a09_row4_col9\" class=\"data row4 col9\" >61.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row5\" class=\"row_heading level0 row5\" >headqa_en</th>\n",
       "      <td id=\"T_62a09_row5_col0\" class=\"data row5 col0\" >38.60</td>\n",
       "      <td id=\"T_62a09_row5_col1\" class=\"data row5 col1\" >36.50</td>\n",
       "      <td id=\"T_62a09_row5_col2\" class=\"data row5 col2\" >38.70</td>\n",
       "      <td id=\"T_62a09_row5_col3\" class=\"data row5 col3\" >39.50</td>\n",
       "      <td id=\"T_62a09_row5_col4\" class=\"data row5 col4\" >37.40</td>\n",
       "      <td id=\"T_62a09_row5_col5\" class=\"data row5 col5\" >38.30</td>\n",
       "      <td id=\"T_62a09_row5_col6\" class=\"data row5 col6\" >40.80</td>\n",
       "      <td id=\"T_62a09_row5_col7\" class=\"data row5 col7\" >38.90</td>\n",
       "      <td id=\"T_62a09_row5_col8\" class=\"data row5 col8\" >47.20</td>\n",
       "      <td id=\"T_62a09_row5_col9\" class=\"data row5 col9\" >37.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row6\" class=\"row_heading level0 row6\" >hellaswag</th>\n",
       "      <td id=\"T_62a09_row6_col0\" class=\"data row6 col0\" >75.90</td>\n",
       "      <td id=\"T_62a09_row6_col1\" class=\"data row6 col1\" >73.30</td>\n",
       "      <td id=\"T_62a09_row6_col2\" class=\"data row6 col2\" >76.20</td>\n",
       "      <td id=\"T_62a09_row6_col3\" class=\"data row6 col3\" >76.80</td>\n",
       "      <td id=\"T_62a09_row6_col4\" class=\"data row6 col4\" >77.60</td>\n",
       "      <td id=\"T_62a09_row6_col5\" class=\"data row6 col5\" >77.50</td>\n",
       "      <td id=\"T_62a09_row6_col6\" class=\"data row6 col6\" >67.20</td>\n",
       "      <td id=\"T_62a09_row6_col7\" class=\"data row6 col7\" >76.20</td>\n",
       "      <td id=\"T_62a09_row6_col8\" class=\"data row6 col8\" >82.10</td>\n",
       "      <td id=\"T_62a09_row6_col9\" class=\"data row6 col9\" >76.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row7\" class=\"row_heading level0 row7\" >logiqa</th>\n",
       "      <td id=\"T_62a09_row7_col0\" class=\"data row7 col0\" >23.66</td>\n",
       "      <td id=\"T_62a09_row7_col1\" class=\"data row7 col1\" >21.81</td>\n",
       "      <td id=\"T_62a09_row7_col2\" class=\"data row7 col2\" >19.51</td>\n",
       "      <td id=\"T_62a09_row7_col3\" class=\"data row7 col3\" >26.11</td>\n",
       "      <td id=\"T_62a09_row7_col4\" class=\"data row7 col4\" >22.89</td>\n",
       "      <td id=\"T_62a09_row7_col5\" class=\"data row7 col5\" >23.50</td>\n",
       "      <td id=\"T_62a09_row7_col6\" class=\"data row7 col6\" >22.89</td>\n",
       "      <td id=\"T_62a09_row7_col7\" class=\"data row7 col7\" >24.88</td>\n",
       "      <td id=\"T_62a09_row7_col8\" class=\"data row7 col8\" >32.57</td>\n",
       "      <td id=\"T_62a09_row7_col9\" class=\"data row7 col9\" >23.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row8\" class=\"row_heading level0 row8\" >mathqa</th>\n",
       "      <td id=\"T_62a09_row8_col0\" class=\"data row8 col0\" >30.00</td>\n",
       "      <td id=\"T_62a09_row8_col1\" class=\"data row8 col1\" >27.50</td>\n",
       "      <td id=\"T_62a09_row8_col2\" class=\"data row8 col2\" >30.20</td>\n",
       "      <td id=\"T_62a09_row8_col3\" class=\"data row8 col3\" >31.60</td>\n",
       "      <td id=\"T_62a09_row8_col4\" class=\"data row8 col4\" >28.90</td>\n",
       "      <td id=\"T_62a09_row8_col5\" class=\"data row8 col5\" >28.90</td>\n",
       "      <td id=\"T_62a09_row8_col6\" class=\"data row8 col6\" >27.80</td>\n",
       "      <td id=\"T_62a09_row8_col7\" class=\"data row8 col7\" >28.60</td>\n",
       "      <td id=\"T_62a09_row8_col8\" class=\"data row8 col8\" >40.00</td>\n",
       "      <td id=\"T_62a09_row8_col9\" class=\"data row8 col9\" >26.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row9\" class=\"row_heading level0 row9\" >mrpc</th>\n",
       "      <td id=\"T_62a09_row9_col0\" class=\"data row9 col0\" >62.75</td>\n",
       "      <td id=\"T_62a09_row9_col1\" class=\"data row9 col1\" >39.95</td>\n",
       "      <td id=\"T_62a09_row9_col2\" class=\"data row9 col2\" >68.63</td>\n",
       "      <td id=\"T_62a09_row9_col3\" class=\"data row9 col3\" >69.12</td>\n",
       "      <td id=\"T_62a09_row9_col4\" class=\"data row9 col4\" >67.65</td>\n",
       "      <td id=\"T_62a09_row9_col5\" class=\"data row9 col5\" >68.14</td>\n",
       "      <td id=\"T_62a09_row9_col6\" class=\"data row9 col6\" >52.70</td>\n",
       "      <td id=\"T_62a09_row9_col7\" class=\"data row9 col7\" >41.67</td>\n",
       "      <td id=\"T_62a09_row9_col8\" class=\"data row9 col8\" >71.81</td>\n",
       "      <td id=\"T_62a09_row9_col9\" class=\"data row9 col9\" >68.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row10\" class=\"row_heading level0 row10\" >openbookqa</th>\n",
       "      <td id=\"T_62a09_row10_col0\" class=\"data row10 col0\" >53.00</td>\n",
       "      <td id=\"T_62a09_row10_col1\" class=\"data row10 col1\" >47.80</td>\n",
       "      <td id=\"T_62a09_row10_col2\" class=\"data row10 col2\" >51.20</td>\n",
       "      <td id=\"T_62a09_row10_col3\" class=\"data row10 col3\" >48.40</td>\n",
       "      <td id=\"T_62a09_row10_col4\" class=\"data row10 col4\" >48.60</td>\n",
       "      <td id=\"T_62a09_row10_col5\" class=\"data row10 col5\" >47.60</td>\n",
       "      <td id=\"T_62a09_row10_col6\" class=\"data row10 col6\" >46.40</td>\n",
       "      <td id=\"T_62a09_row10_col7\" class=\"data row10 col7\" >44.80</td>\n",
       "      <td id=\"T_62a09_row10_col8\" class=\"data row10 col8\" >49.80</td>\n",
       "      <td id=\"T_62a09_row10_col9\" class=\"data row10 col9\" >50.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row11\" class=\"row_heading level0 row11\" >piqa</th>\n",
       "      <td id=\"T_62a09_row11_col0\" class=\"data row11 col0\" >78.50</td>\n",
       "      <td id=\"T_62a09_row11_col1\" class=\"data row11 col1\" >77.90</td>\n",
       "      <td id=\"T_62a09_row11_col2\" class=\"data row11 col2\" >77.20</td>\n",
       "      <td id=\"T_62a09_row11_col3\" class=\"data row11 col3\" >76.70</td>\n",
       "      <td id=\"T_62a09_row11_col4\" class=\"data row11 col4\" >77.30</td>\n",
       "      <td id=\"T_62a09_row11_col5\" class=\"data row11 col5\" >77.20</td>\n",
       "      <td id=\"T_62a09_row11_col6\" class=\"data row11 col6\" >74.50</td>\n",
       "      <td id=\"T_62a09_row11_col7\" class=\"data row11 col7\" >74.70</td>\n",
       "      <td id=\"T_62a09_row11_col8\" class=\"data row11 col8\" >80.50</td>\n",
       "      <td id=\"T_62a09_row11_col9\" class=\"data row11 col9\" >78.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row12\" class=\"row_heading level0 row12\" >qnli</th>\n",
       "      <td id=\"T_62a09_row12_col0\" class=\"data row12 col0\" >49.80</td>\n",
       "      <td id=\"T_62a09_row12_col1\" class=\"data row12 col1\" >49.90</td>\n",
       "      <td id=\"T_62a09_row12_col2\" class=\"data row12 col2\" >50.10</td>\n",
       "      <td id=\"T_62a09_row12_col3\" class=\"data row12 col3\" >49.40</td>\n",
       "      <td id=\"T_62a09_row12_col4\" class=\"data row12 col4\" >52.10</td>\n",
       "      <td id=\"T_62a09_row12_col5\" class=\"data row12 col5\" >49.30</td>\n",
       "      <td id=\"T_62a09_row12_col6\" class=\"data row12 col6\" >50.00</td>\n",
       "      <td id=\"T_62a09_row12_col7\" class=\"data row12 col7\" >49.40</td>\n",
       "      <td id=\"T_62a09_row12_col8\" class=\"data row12 col8\" >51.30</td>\n",
       "      <td id=\"T_62a09_row12_col9\" class=\"data row12 col9\" >49.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row13\" class=\"row_heading level0 row13\" >qqp</th>\n",
       "      <td id=\"T_62a09_row13_col0\" class=\"data row13 col0\" >40.70</td>\n",
       "      <td id=\"T_62a09_row13_col1\" class=\"data row13 col1\" >37.50</td>\n",
       "      <td id=\"T_62a09_row13_col2\" class=\"data row13 col2\" >41.30</td>\n",
       "      <td id=\"T_62a09_row13_col3\" class=\"data row13 col3\" >38.30</td>\n",
       "      <td id=\"T_62a09_row13_col4\" class=\"data row13 col4\" >47.50</td>\n",
       "      <td id=\"T_62a09_row13_col5\" class=\"data row13 col5\" >38.20</td>\n",
       "      <td id=\"T_62a09_row13_col6\" class=\"data row13 col6\" >39.00</td>\n",
       "      <td id=\"T_62a09_row13_col7\" class=\"data row13 col7\" >62.40</td>\n",
       "      <td id=\"T_62a09_row13_col8\" class=\"data row13 col8\" >75.50</td>\n",
       "      <td id=\"T_62a09_row13_col9\" class=\"data row13 col9\" >40.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row14\" class=\"row_heading level0 row14\" >rte</th>\n",
       "      <td id=\"T_62a09_row14_col0\" class=\"data row14 col0\" >61.73</td>\n",
       "      <td id=\"T_62a09_row14_col1\" class=\"data row14 col1\" >52.71</td>\n",
       "      <td id=\"T_62a09_row14_col2\" class=\"data row14 col2\" >66.43</td>\n",
       "      <td id=\"T_62a09_row14_col3\" class=\"data row14 col3\" >62.82</td>\n",
       "      <td id=\"T_62a09_row14_col4\" class=\"data row14 col4\" >62.82</td>\n",
       "      <td id=\"T_62a09_row14_col5\" class=\"data row14 col5\" >69.68</td>\n",
       "      <td id=\"T_62a09_row14_col6\" class=\"data row14 col6\" >57.76</td>\n",
       "      <td id=\"T_62a09_row14_col7\" class=\"data row14 col7\" >63.54</td>\n",
       "      <td id=\"T_62a09_row14_col8\" class=\"data row14 col8\" >74.01</td>\n",
       "      <td id=\"T_62a09_row14_col9\" class=\"data row14 col9\" >51.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row15\" class=\"row_heading level0 row15\" >sciq</th>\n",
       "      <td id=\"T_62a09_row15_col0\" class=\"data row15 col0\" >93.90</td>\n",
       "      <td id=\"T_62a09_row15_col1\" class=\"data row15 col1\" >93.60</td>\n",
       "      <td id=\"T_62a09_row15_col2\" class=\"data row15 col2\" >93.90</td>\n",
       "      <td id=\"T_62a09_row15_col3\" class=\"data row15 col3\" >94.50</td>\n",
       "      <td id=\"T_62a09_row15_col4\" class=\"data row15 col4\" >93.70</td>\n",
       "      <td id=\"T_62a09_row15_col5\" class=\"data row15 col5\" >94.20</td>\n",
       "      <td id=\"T_62a09_row15_col6\" class=\"data row15 col6\" >92.60</td>\n",
       "      <td id=\"T_62a09_row15_col7\" class=\"data row15 col7\" >92.90</td>\n",
       "      <td id=\"T_62a09_row15_col8\" class=\"data row15 col8\" >96.20</td>\n",
       "      <td id=\"T_62a09_row15_col9\" class=\"data row15 col9\" >93.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row16\" class=\"row_heading level0 row16\" >social_iqa</th>\n",
       "      <td id=\"T_62a09_row16_col0\" class=\"data row16 col0\" >49.20</td>\n",
       "      <td id=\"T_62a09_row16_col1\" class=\"data row16 col1\" >44.60</td>\n",
       "      <td id=\"T_62a09_row16_col2\" class=\"data row16 col2\" >48.90</td>\n",
       "      <td id=\"T_62a09_row16_col3\" class=\"data row16 col3\" >48.00</td>\n",
       "      <td id=\"T_62a09_row16_col4\" class=\"data row16 col4\" >47.40</td>\n",
       "      <td id=\"T_62a09_row16_col5\" class=\"data row16 col5\" >49.00</td>\n",
       "      <td id=\"T_62a09_row16_col6\" class=\"data row16 col6\" >45.30</td>\n",
       "      <td id=\"T_62a09_row16_col7\" class=\"data row16 col7\" >49.00</td>\n",
       "      <td id=\"T_62a09_row16_col8\" class=\"data row16 col8\" >51.40</td>\n",
       "      <td id=\"T_62a09_row16_col9\" class=\"data row16 col9\" >46.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row17\" class=\"row_heading level0 row17\" >sst</th>\n",
       "      <td id=\"T_62a09_row17_col0\" class=\"data row17 col0\" >49.08</td>\n",
       "      <td id=\"T_62a09_row17_col1\" class=\"data row17 col1\" >48.51</td>\n",
       "      <td id=\"T_62a09_row17_col2\" class=\"data row17 col2\" >83.26</td>\n",
       "      <td id=\"T_62a09_row17_col3\" class=\"data row17 col3\" >51.95</td>\n",
       "      <td id=\"T_62a09_row17_col4\" class=\"data row17 col4\" >75.80</td>\n",
       "      <td id=\"T_62a09_row17_col5\" class=\"data row17 col5\" >87.27</td>\n",
       "      <td id=\"T_62a09_row17_col6\" class=\"data row17 col6\" >55.96</td>\n",
       "      <td id=\"T_62a09_row17_col7\" class=\"data row17 col7\" >64.45</td>\n",
       "      <td id=\"T_62a09_row17_col8\" class=\"data row17 col8\" >88.30</td>\n",
       "      <td id=\"T_62a09_row17_col9\" class=\"data row17 col9\" >60.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row18\" class=\"row_heading level0 row18\" >wic</th>\n",
       "      <td id=\"T_62a09_row18_col0\" class=\"data row18 col0\" >49.53</td>\n",
       "      <td id=\"T_62a09_row18_col1\" class=\"data row18 col1\" >49.53</td>\n",
       "      <td id=\"T_62a09_row18_col2\" class=\"data row18 col2\" >49.06</td>\n",
       "      <td id=\"T_62a09_row18_col3\" class=\"data row18 col3\" >49.84</td>\n",
       "      <td id=\"T_62a09_row18_col4\" class=\"data row18 col4\" >48.12</td>\n",
       "      <td id=\"T_62a09_row18_col5\" class=\"data row18 col5\" >48.28</td>\n",
       "      <td id=\"T_62a09_row18_col6\" class=\"data row18 col6\" >48.59</td>\n",
       "      <td id=\"T_62a09_row18_col7\" class=\"data row18 col7\" >53.92</td>\n",
       "      <td id=\"T_62a09_row18_col8\" class=\"data row18 col8\" >61.44</td>\n",
       "      <td id=\"T_62a09_row18_col9\" class=\"data row18 col9\" >50.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row19\" class=\"row_heading level0 row19\" >winogrande</th>\n",
       "      <td id=\"T_62a09_row19_col0\" class=\"data row19 col0\" >68.90</td>\n",
       "      <td id=\"T_62a09_row19_col1\" class=\"data row19 col1\" >67.00</td>\n",
       "      <td id=\"T_62a09_row19_col2\" class=\"data row19 col2\" >70.50</td>\n",
       "      <td id=\"T_62a09_row19_col3\" class=\"data row19 col3\" >69.40</td>\n",
       "      <td id=\"T_62a09_row19_col4\" class=\"data row19 col4\" >69.90</td>\n",
       "      <td id=\"T_62a09_row19_col5\" class=\"data row19 col5\" >69.10</td>\n",
       "      <td id=\"T_62a09_row19_col6\" class=\"data row19 col6\" >68.30</td>\n",
       "      <td id=\"T_62a09_row19_col7\" class=\"data row19 col7\" >66.60</td>\n",
       "      <td id=\"T_62a09_row19_col8\" class=\"data row19 col8\" >73.40</td>\n",
       "      <td id=\"T_62a09_row19_col9\" class=\"data row19 col9\" >67.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row20\" class=\"row_heading level0 row20\" >wnli</th>\n",
       "      <td id=\"T_62a09_row20_col0\" class=\"data row20 col0\" >47.89</td>\n",
       "      <td id=\"T_62a09_row20_col1\" class=\"data row20 col1\" >52.11</td>\n",
       "      <td id=\"T_62a09_row20_col2\" class=\"data row20 col2\" >52.11</td>\n",
       "      <td id=\"T_62a09_row20_col3\" class=\"data row20 col3\" >45.07</td>\n",
       "      <td id=\"T_62a09_row20_col4\" class=\"data row20 col4\" >47.89</td>\n",
       "      <td id=\"T_62a09_row20_col5\" class=\"data row20 col5\" >42.25</td>\n",
       "      <td id=\"T_62a09_row20_col6\" class=\"data row20 col6\" >52.11</td>\n",
       "      <td id=\"T_62a09_row20_col7\" class=\"data row20 col7\" >43.66</td>\n",
       "      <td id=\"T_62a09_row20_col8\" class=\"data row20 col8\" >63.38</td>\n",
       "      <td id=\"T_62a09_row20_col9\" class=\"data row20 col9\" >56.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62a09_level0_row21\" class=\"row_heading level0 row21\" >wsc</th>\n",
       "      <td id=\"T_62a09_row21_col0\" class=\"data row21 col0\" >35.58</td>\n",
       "      <td id=\"T_62a09_row21_col1\" class=\"data row21 col1\" >59.62</td>\n",
       "      <td id=\"T_62a09_row21_col2\" class=\"data row21 col2\" >50.96</td>\n",
       "      <td id=\"T_62a09_row21_col3\" class=\"data row21 col3\" >36.54</td>\n",
       "      <td id=\"T_62a09_row21_col4\" class=\"data row21 col4\" >63.46</td>\n",
       "      <td id=\"T_62a09_row21_col5\" class=\"data row21 col5\" >64.42</td>\n",
       "      <td id=\"T_62a09_row21_col6\" class=\"data row21 col6\" >36.54</td>\n",
       "      <td id=\"T_62a09_row21_col7\" class=\"data row21 col7\" >36.54</td>\n",
       "      <td id=\"T_62a09_row21_col8\" class=\"data row21 col8\" >63.46</td>\n",
       "      <td id=\"T_62a09_row21_col9\" class=\"data row21 col9\" >37.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc038955510>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the coloring to the DataFrame\n",
    "styled_df = models_by_task.style.map(colorize)\n",
    "\n",
    "# Display the DataFrame\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7eadf-f6de-4a25-8efc-c11df30d12d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
